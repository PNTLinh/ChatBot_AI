import os
import streamlit as st  
from dotenv import load_dotenv  
from typing import Dict, List, Any, Optional
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema.document import Document
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
import time
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from google.generativeai.types.safety_types import (
    HarmCategory, HarmBlockThreshold
)
from langchain.chains import RetrievalQA
from langchain.chains import ConversationChain
import os
from langchain.schema import HumanMessage, AIMessage

# Import t·ª´ module seed_data
from seed_data import seed_faiss, seed_faiss_live

# Thi·∫øt l·∫≠p cache cho c√°c h√†m t·ªën t√†i nguy√™n
@st.cache_resource(ttl=3600)
def get_embeddings(api_key):
    """Cache embeddings ƒë·ªÉ tr√°nh t·∫°o l·∫°i m·ªói khi refresh"""
    return GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=api_key
    )

@st.cache_resource(ttl=3600)
def load_faiss_index(collection_name, _embeddings):
    """Cache FAISS index ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô"""
    index_path = f"faiss_indexes/{collection_name}"
    if not os.path.exists(index_path):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y ch·ªâ m·ª•c FAISS t·∫°i: {index_path}")
    
    return FAISS.load_local(
        folder_path=index_path,
        embeddings=_embeddings,
        allow_dangerous_deserialization=True,
        index_name=collection_name
    )

# C·∫•u h√¨nh trang
def setup_page():
    """C·∫•u h√¨nh c√°c th√¥ng s·ªë cho trang Streamlit"""
    st.set_page_config(
        page_title="H√†nh Ch√≠nh C√¥ng AI",  
        page_icon="üèõÔ∏è",  
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # T√πy ch·ªânh CSS ƒë·ªÉ c·∫£i thi·ªán giao di·ªán
    st.markdown("""
    <style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .element-container img {
        background-color: #f0f2f6;
        border-radius: 0.5rem;
        padding: 0.5rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #4CAF50;
        color: white;
        border: none;
        padding: 10px;
        border-radius: 5px;
        transition: background-color 0.3s;
    }
    .stButton>button:hover {
        background-color: #45a049;
    }
    .stTextInput>div>div>input {
        padding: 0.7rem;
        border-radius: 5px;
        border: 1px solid #ddd;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .chat-message.user {
        background-color: #EFF6FF;
        border-left: 5px solid #3B82F6;
    }
    .chat-message.bot {
        background-color: #F0FDF4;
        border-left: 5px solid #10B981;
    }
    .source-doc {
        background-color: #F7F7F7;
        padding: 0.5rem;
        border-radius: 5px;
        margin-top: 0.5rem;
        font-size: 0.85rem;
    }
    div[data-testid="stSidebarUserContent"] {
        padding-top: 1rem;
    }
    .sidebar-title {
        font-size: 1.2rem;
        font-weight: bold;
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)

# Ki·ªÉm tra v√† thi·∫øt l·∫≠p API key
def check_api_key() -> bool:
    """Ki·ªÉm tra xem ƒë√£ c√≥ API key h·ª£p l·ªá ch∆∞a"""
    api_key = st.session_state.get("gemini_api_key", os.getenv("GOOGLE_API_KEY", ""))
    if not api_key:
        st.sidebar.error("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ƒë·ªÉ s·ª≠ d·ª•ng ·ª©ng d·ª•ng")
        return False
    
    # L∆∞u API key v√†o session state n·∫øu ch∆∞a c√≥
    if "gemini_api_key" not in st.session_state:
        st.session_state["gemini_api_key"] = api_key
    
    # Ki·ªÉm tra API key c√≥ h·ª£p l·ªá kh√¥ng
    try:
        # Th·ª≠ t·∫°o embeddings ƒë·ªÉ ki·ªÉm tra API key
        _ = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=api_key
        )
        return True
    except Exception as e:
        st.sidebar.error(f"‚ùå API Key kh√¥ng h·ª£p l·ªá: {str(e)}")
        return False

# Thi·∫øt l·∫≠p sidebar
def setup_sidebar() -> str:
    """Thi·∫øt l·∫≠p sidebar v·ªõi c√°c t√πy ch·ªçn v√† tr·∫£ v·ªÅ t√™n collection ƒë·ªÉ truy v·∫•n"""
    with st.sidebar:
        st.title("üîß T√πy ch·ªçn")
        
        # Tabs cho sidebar
        data_tab, settings_tab, about_tab = st.tabs(["üìö D·ªØ li·ªáu", "‚öôÔ∏è C√†i ƒë·∫∑t", "‚ÑπÔ∏è Th√¥ng tin"])
        
        with data_tab:
            st.markdown("<div class='sidebar-title'>C·∫•u h√¨nh d·ªØ li·ªáu</div>", unsafe_allow_html=True)
            collection_to_query = st.text_input(
                "T√™n d·ªØ li·ªáu ƒë·ªÉ truy v·∫•n:", 
                value=st.session_state.get("collection_name", "tthc_index"),
                help="Nh·∫≠p t√™n c·ªßa ch·ªâ m·ª•c FAISS b·∫°n mu·ªën truy v·∫•n",
                key="collection_input"
            )
            
            # L∆∞u collection name v√†o session state
            if collection_to_query != st.session_state.get("collection_name", ""):
                st.session_state["collection_name"] = collection_to_query
            
            st.divider()
            
            # Ph·∫ßn t·∫£i d·ªØ li·ªáu t·ª´ file JSON
            st.markdown("<div class='sidebar-title'>T·∫£i d·ªØ li·ªáu</div>", unsafe_allow_html=True)
            st.info("S·ª≠ d·ª•ng d·ªØ li·ªáu TTHC.json t·ª´ Google Drive ho·∫∑c m√°y t√≠nh")
            
            # X·ª≠ l√Ω file t·ª´ Google Drive ho·∫∑c upload
            col1, col2 = st.columns(2)
            with col1:
                source_option = st.radio(
                    "Ngu·ªìn d·ªØ li·ªáu:",
                    ["Google Drive", "Upload File"],
                    index=0
                )
            
            index_name = st.text_input(
                "T√™n ch·ªâ m·ª•c FAISS:",
                value=st.session_state.get("index_name", "tthc_index"),
                help="Nh·∫≠p t√™n cho ch·ªâ m·ª•c FAISS"
            )
            
            # L∆∞u index name v√†o session state
            if index_name != st.session_state.get("index_name", ""):
                st.session_state["index_name"] = index_name
            
            if source_option == "Google Drive":
                drive_path = st.text_input(
                    "ƒê∆∞·ªùng d·∫´n ƒë·∫øn file TTHC.json:",
                    value=st.session_state.get("drive_path", "/content/drive/MyDrive/DS_6/Datasets/TTHC.json"),
                    help="ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file TTHC.json"
                )
                
                # L∆∞u drive path v√†o session state
                if drive_path != st.session_state.get("drive_path", ""):
                    st.session_state["drive_path"] = drive_path
                
                # N√∫t t·∫£i d·ªØ li·ªáu t·ª´ Google Drive
                if st.button("üì• T·∫£i t·ª´ Google Drive"):
                    if not index_name:
                        st.error("Vui l√≤ng nh·∫≠p t√™n ch·ªâ m·ª•c!")
                    else:
                        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ Google Drive..."):
                            try:
                                directory, filename = os.path.split(drive_path)
                                seed_faiss(
                                    index_name, 
                                    filename, 
                                    directory, 
                                    google_api_key=api_key
                                )
                                st.success(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng v√†o ch·ªâ m·ª•c '{index_name}'!")
                                
                                # C·∫≠p nh·∫≠t collection name n·∫øu ng∆∞·ªùi d√πng mu·ªën s·ª≠ d·ª•ng ch·ªâ m·ª•c v·ª´a t·∫°o
                                st.session_state["collection_name"] = index_name
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}")
            else:
                # Upload file
                uploaded_file = st.file_uploader("Upload file TTHC.json", type=["json"])
                if uploaded_file is not None:
                    if st.button("üì• X·ª≠ l√Ω file ƒë√£ upload"):
                        if not index_name:
                            st.error("Vui l√≤ng nh·∫≠p t√™n ch·ªâ m·ª•c!")
                        else:
                            with st.spinner("ƒêang x·ª≠ l√Ω file ƒë√£ upload..."):
                                try:
                                    # L∆∞u file t·∫°m th·ªùi
                                    temp_dir = "temp_uploads"
                                    os.makedirs(temp_dir, exist_ok=True)
                                    file_path = os.path.join(temp_dir, "temp_tthc.json")
                                    
                                    with open(file_path, "wb") as f:
                                        f.write(uploaded_file.getbuffer())
                                    
                                    # X·ª≠ l√Ω file ƒë√£ upload
                                    seed_faiss(
                                        index_name,
                                        "temp_tthc.json",
                                        temp_dir,
                                        google_api_key=api_key
                                    )
                                    st.success(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng v√†o ch·ªâ m·ª•c '{index_name}'!")
                                    
                                    # C·∫≠p nh·∫≠t collection name
                                    st.session_state["collection_name"] = index_name
                                    st.experimental_rerun()
                                except Exception as e:
                                    st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file: {str(e)}")
        
        with settings_tab:
            st.markdown("<div class='sidebar-title'>API v√† M√¥ h√¨nh</div>", unsafe_allow_html=True)
            api_key = st.text_input(
                "Gemini API Key", 
                type="password", 
                value=st.session_state.get("gemini_api_key", os.getenv("GOOGLE_API_KEY", "")),
                help="Nh·∫≠p Google API Key ƒë·ªÉ s·ª≠ d·ª•ng Gemini"
            )
            
            # L∆∞u API key v√†o session state
            if api_key != st.session_state.get("gemini_api_key", ""):
                st.session_state["gemini_api_key"] = api_key
            
            st.divider()
            
            st.markdown("<div class='sidebar-title'>Th√¥ng s·ªë RAG</div>", unsafe_allow_html=True)
            # S·ªë l∆∞·ª£ng t√†i li·ªáu tr·∫£ v·ªÅ t·ª´ retriever
            k_documents = st.slider(
                "S·ªë l∆∞·ª£ng t√†i li·ªáu k·∫øt qu·∫£:", 
                min_value=1, 
                max_value=10, 
                value=st.session_state.get("k_documents", 5),
                help="S·ªë l∆∞·ª£ng t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi"
            )
            
            # L∆∞u k_documents v√†o session state
            if k_documents != st.session_state.get("k_documents", 5):
                st.session_state["k_documents"] = k_documents
            
            # Nhi·ªát ƒë·ªô (temperature) c·ªßa m√¥ h√¨nh
            temperature = st.slider(
                "ƒê·ªô s√°ng t·∫°o (Temperature):", 
                min_value=0.0, 
                max_value=1.0, 
                value=st.session_state.get("temperature", 0.7),
                step=0.1,
                help="Gi√° tr·ªã th·∫•p h∆°n cho c√¢u tr·∫£ l·ªùi nh·∫•t qu√°n, gi√° tr·ªã cao h∆°n cho c√¢u tr·∫£ l·ªùi s√°ng t·∫°o"
            )
            
            # L∆∞u temperature v√†o session state
            if temperature != st.session_state.get("temperature", 0.7):
                st.session_state["temperature"] = temperature
            
            # Th√™m t√πy ch·ªçn cho m√¥ h√¨nh ng√¥n ng·ªØ
            model_options = ["gemini-pro", "gemini-1.5-pro"]
            selected_model = st.selectbox(
                "M√¥ h√¨nh ng√¥n ng·ªØ:",
                options=model_options,
                index=model_options.index(st.session_state.get("selected_model", "gemini-pro")),
                help="Ch·ªçn m√¥ h√¨nh ng√¥n ng·ªØ ƒë·ªÉ s·ª≠ d·ª•ng"
            )
            
            # L∆∞u l·ª±a ch·ªçn m√¥ h√¨nh v√†o session state
            if selected_model != st.session_state.get("selected_model", "gemini-pro"):
                st.session_state["selected_model"] = selected_model
            
            # N√∫t x√≥a l·ªãch s·ª≠ chat
            st.divider()
            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat"):
                st.session_state.messages = [
                    {"role": "assistant", "content": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI h√†nh ch√≠nh c√¥ng. B·∫°n c·∫ßn gi√∫p ƒë·ª° g√¨ v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh?"}
                ]
                if "langchain_messages" in st.session_state:
                    st.session_state.langchain_messages = []
                st.success("ƒê√£ x√≥a l·ªãch s·ª≠ chat!")
        
        with about_tab:
            st.markdown("<div class='sidebar-title'>Gi·ªõi thi·ªáu</div>", unsafe_allow_html=True)
            st.markdown("""
            **Tr·ª£ l√Ω H√†nh Ch√≠nh C√¥ng AI** l√† m·ªôt chatbot th√¥ng minh s·ª≠ d·ª•ng c√¥ng ngh·ªá RAG (Retrieval-Augmented Generation) ƒë·ªÉ cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh t·∫°i Vi·ªát Nam.
            
            **C√¥ng ngh·ªá s·ª≠ d·ª•ng:**
            - üß† Google Gemini Pro
            - üîç FAISS Vector Database
            - üîÑ LangChain Framework
            - üåê Streamlit UI
            
            **T√≠nh nƒÉng ch√≠nh:**
            - T√¨m ki·∫øm th√¥ng tin v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh
            - Gi·∫£i ƒë√°p c√°c th·∫Øc m·∫Øc v·ªÅ quy tr√¨nh, h·ªì s∆°, l·ªá ph√≠
            - Tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu ch√≠nh th·ªëng
            - Tr√≠ch d·∫´n ngu·ªìn th√¥ng tin r√µ r√†ng
            
            **Li√™n h·ªá**: support@hanhchinhcong.ai
            """)
            
            # Th√™m ph·∫ßn th·ªëng k√™
            if "query_count" not in st.session_state:
                st.session_state.query_count = 0
                
            st.divider()
            st.markdown("<div class='sidebar-title'>Th·ªëng k√™</div>", unsafe_allow_html=True)
            st.metric("S·ªë c√¢u h·ªèi ƒë√£ x·ª≠ l√Ω", st.session_state.query_count)
            
            # Hi·ªÉn th·ªã th·ªùi gian phi√™n l√†m vi·ªác
            if "session_start" not in st.session_state:
                st.session_state.session_start = time.time()
            
            session_duration = int(time.time() - st.session_state.session_start)
            minutes, seconds = divmod(session_duration, 60)
            hours, minutes = divmod(minutes, 60)
            
            if hours > 0:
                session_time = f"{hours} gi·ªù {minutes} ph√∫t"
            else:
                session_time = f"{minutes} ph√∫t {seconds} gi√¢y"
                
            st.metric("Th·ªùi gian phi√™n l√†m vi·ªác", session_time)
    
    return collection_to_query

# Kh·ªüi t·∫°o retriever cho RAG
def get_gemini_retriever(collection_name: str) -> Any:
    """Kh·ªüi t·∫°o retriever s·ª≠ d·ª•ng Gemini v√† FAISS"""
    try:
        # T·∫°o embeddings
        api_key = st.session_state.get("gemini_api_key", os.getenv("GOOGLE_API_KEY"))
        embeddings = get_embeddings(api_key)
        
        # T·∫£i vectorstore
        vectorstore = FAISS.load_local(
            folder_path=f"/content/faiss_indexes/{collection_name}",
            embeddings=embeddings,
            index_name=collection_name, 
            allow_dangerous_deserialization=True  # Cho ph√©p load pickle
        )
        
        # T·∫°o v√† tr·∫£ v·ªÅ retriever
        k_documents = st.session_state.get("k_documents", 5)
        return vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": k_documents}
        )
    except Exception as e:
        raise ValueError(f"L·ªói khi t·∫°o retriever: {str(e)}")

# Kh·ªüi t·∫°o agent RAG s·ª≠ d·ª•ng Gemini
# Kh·ªüi t·∫°o agent RAG s·ª≠ d·ª•ng Gemini
def get_gemini_agent(retriever): # <--- B·ªè tham s·ªë msgs ·ªü ƒë√¢y
    """T·∫°o agent RAG s·ª≠ d·ª•ng Gemini v√† retriever ƒë√£ cho"""
    try:
        # L·∫•y th√¥ng s·ªë c·∫•u h√¨nh t·ª´ session state
        api_key = st.session_state.get("gemini_api_key", os.getenv("GOOGLE_API_KEY"))
        temperature = st.session_state.get("temperature", 0.7)
        model_name = st.session_state.get("selected_model", "gemini-1.5-flash")

        # Kh·ªüi t·∫°o m√¥ h√¨nh Gemini
        llm = GoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=temperature,
            top_p=0.95,
            top_k=40,
            max_output_tokens=2048,
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )

        # B·ªè kh·ªüi t·∫°o ConversationBufferMemory ·ªü ƒë√¢y

        # ƒê·ªãnh nghƒ©a template cho prompt h·ªá th·ªëng
        # V·∫´n gi·ªØ input variables chat_history, context, query v√¨ ta s·∫Ω truy·ªÅn ch√∫ng th·ªß c√¥ng
        system_template = """
        B·∫°n l√† tr·ª£ l√Ω AI h√†nh ch√≠nh c√¥ng c·ªßa Vi·ªát Nam, chuy√™n gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh,
        gi·∫•y t·ªù, v√† c√°c quy tr√¨nh li√™n quan ƒë·∫øn d·ªãch v·ª• c√¥ng. H√£y s·ª≠ d·ª•ng th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.
        L·ªãch s·ª≠ cu·ªôc h·ªôi tho·∫°i:
        {chat_history}
        H√£y tr·∫£ l·ªùi theo c√°c nguy√™n t·∫Øc sau:
        1. Tr·∫£ l·ªùi ƒë√∫ng v·ªÅ n·ªôi dung th·ªß t·ª•c h√†nh ch√≠nh d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p
        2. Gi·∫£i th√≠ch c√°c b∆∞·ªõc th·ª±c hi·ªán m·ªôt c√°ch r√µ r√†ng v√† d·ªÖ hi·ªÉu
        3. Li·ªát k√™ ƒë·∫ßy ƒë·ªß th√†nh ph·∫ßn h·ªì s∆° c·∫ßn thi·∫øt n·∫øu ƒë∆∞·ª£c h·ªèi
        4. Cung c·∫•p th√¥ng tin v·ªÅ th·ªùi gian gi·∫£i quy·∫øt v√† l·ªá ph√≠ n·∫øu c√≥
        5. N√™u r√µ c∆° quan th·ª±c hi·ªán th·ªß t·ª•c
        6. N·∫øu th√¥ng tin ƒë∆∞·ª£c cung c·∫•p kh√¥ng ƒë·ªß, h√£y g·ª£i √Ω ng∆∞·ªùi d√πng cung c·∫•p th√™m th√¥ng tin
        7. N·∫øu kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y th·ª´a nh·∫≠n ƒëi·ªÅu ƒë√≥ v√† ƒë·ªÅ xu·∫•t ng∆∞·ªùi d√πng li√™n h·ªá tr·ª±c ti·∫øp v·ªõi c∆° quan h√†nh ch√≠nh c√≥ th·∫©m quy·ªÅn
        8. Tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† s√∫c t√≠ch, s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng markdown ƒë·ªÉ d·ªÖ ƒë·ªçc
        9. Th√¥ng tin li·ªát k√™ n√™n s·ª≠ d·ª•ng d·∫°ng g·∫°ch ƒë·∫ßu d√≤ng cho d·ªÖ ƒë·ªçc

        Th√¥ng tin li√™n quan t·ª´ c∆° s·ªü d·ªØ li·ªáu th·ªß t·ª•c h√†nh ch√≠nh:
        {context}

        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {question} # Bi·∫øn n√†y kh·ªõp v·ªõi key "query" ta s·∫Ω truy·ªÅn v√†o

        Tr·∫£ l·ªùi (s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng markdown cho d·ªÖ ƒë·ªçc):
        """

        # T·∫°o prompt template
        prompt = PromptTemplate(
            template=system_template,
            # C√°c bi·∫øn n√†y ph·∫£i c√≥ v√¨ ch√∫ng ƒë∆∞·ª£c d√πng trong template
            input_variables=["chat_history","context", "question"]
        )

        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": prompt}
        )


        # Tr·∫£ v·ªÅ chain, kh√¥ng c·∫ßn tr·∫£ v·ªÅ memory n·ªØa
        return qa_chain
    except Exception as e:
        raise ValueError(f"L·ªói khi kh·ªüi t·∫°o m√¥ h√¨nh: {str(e)}")

# Hi·ªÉn th·ªã li√™n k·∫øt nhanh
def display_quick_links():
    """Hi·ªÉn th·ªã c√°c li√™n k·∫øt nhanh ƒë·∫øn c√°c th·ªß t·ª•c ph·ªï bi·∫øn"""
    st.subheader("üí° Th·ªß t·ª•c ph·ªï bi·∫øn")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ƒêƒÉng k√Ω k·∫øt h√¥n"):
            st.session_state.pending_question = "Th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n c·∫ßn nh·ªØng gi·∫•y t·ªù g√¨?"
            st.rerun()
    
    with col2:
        if st.button("C·∫•p cƒÉn c∆∞·ªõc c√¥ng d√¢n"):
            st.session_state.pending_question = "Th·ªß t·ª•c c·∫•p cƒÉn c∆∞·ªõc c√¥ng d√¢n g·ªìm nh·ªØng b∆∞·ªõc n√†o?"
            st.rerun()
    
    with col3:
        if st.button("ƒêƒÉng k√Ω kinh doanh"):
            st.session_state.pending_question = "Th·ªß t·ª•c ƒëƒÉng k√Ω kinh doanh h·ªô c√° th·ªÉ c·∫ßn nh·ªØng gi·∫•y t·ªù g√¨?"
            st.rerun()
# Thi·∫øt l·∫≠p giao di·ªán chat
def setup_chat_interface():
    """Thi·∫øt l·∫≠p giao di·ªán chat v·ªõi l·ªãch s·ª≠ tin nh·∫Øn"""
    # Container ch√≠nh
    main_container = st.container()
    with main_container:
        # Header
        col1, col2 = st.columns([1, 6])
        with col1:
            st.image("https://raw.githubusercontent.com/vanhung4499/temp/main/icons/government.png", width=80)
        with col2:
            st.title("üèõÔ∏è Tr·ª£ l√Ω H√†nh ch√≠nh c√¥ng AI")
            st.caption("Tr·ª£ l√Ω AI ƒë∆∞·ª£c trang b·ªã c√¥ng ngh·ªá RAG (Retrieval-Augmented Generation) v√† Google Gemini")
        
        st.divider()
        
        # Hi·ªÉn th·ªã c√°c li√™n k·∫øt nhanh
        display_quick_links()
    
    # Kh·ªüi t·∫°o l·ªãch s·ª≠ tin nh·∫Øn n·∫øu ch∆∞a c√≥
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI h√†nh ch√≠nh c√¥ng. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu v·ªÅ c√°c th·ªß t·ª•c h√†nh ch√≠nh, h·ªì s∆° c·∫ßn thi·∫øt, quy tr√¨nh th·ª±c hi·ªán, th·ªùi gian v√† l·ªá ph√≠. B·∫°n c·∫ßn h·ªó tr·ª£ v·∫•n ƒë·ªÅ g√¨?"}
        ]
    
    # TH√äM V√ÄO ƒê√ÇY: X·ª≠ l√Ω pending_question n·∫øu c√≥
    if "pending_question" in st.session_state and st.session_state.pending_question:
        # Th√™m c√¢u h·ªèi v√†o l·ªãch s·ª≠ tin nh·∫Øn
        st.session_state.messages.append({"role": "human", "content": st.session_state.pending_question})
        
        # X√≥a pending_question sau khi ƒë√£ x·ª≠ l√Ω ƒë·ªÉ tr√°nh v√≤ng l·∫∑p
        question = st.session_state.pending_question
        st.session_state.pending_question = ""
        
        # QUAN TR·ªåNG: ƒê·∫∑t m·ªôt c·ªù ƒë·ªÉ x·ª≠ l√Ω c√¢u tr·∫£ l·ªùi ·ªü ph·∫ßn kh√°c c·ªßa code
        # B·∫°n c·∫ßn x·ª≠ l√Ω c√¢u tr·∫£ l·ªùi ·ªü main() ho·∫∑c n∆°i kh√°c sau khi setup_chat_interface() ƒë∆∞·ª£c g·ªçi
        st.session_state.needs_answer = True
        st.session_state.current_question = question
    
    # Hi·ªÉn th·ªã tin nh·∫Øn hi·ªán c√≥ v·ªõi CSS ƒë∆∞·ª£c c·∫£i thi·ªán
    messages_container = st.container(height=500)
    with messages_container:
        for msg in st.session_state.messages:
            if msg["role"] == "human":
                with st.chat_message("user"):
                    st.markdown(f"<div class='chat-message user'>{msg['content']}</div>", unsafe_allow_html=True)
            else:
                with st.chat_message("assistant"):
                    st.markdown(f"<div class='chat-message bot'>{msg['content']}</div>", unsafe_allow_html=True)
    
    # Tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng l·ªãch s·ª≠ tin nh·∫Øn cho LangChain
    return StreamlitChatMessageHistory(key="langchain_messages")

# X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng
# X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng
# X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng
def handle_user_input(msgs, agent_executor):
    """X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng v√† t·∫°o ph·∫£n h·ªìi t·ª´ tr·ª£ l√Ω"""
    # Ki·ªÉm tra c√¢u h·ªèi t·ª´ n√∫t li√™n k·∫øt nhanh
    prompt = None
    if "pending_question" in st.session_state and st.session_state.pending_question:
        prompt = st.session_state.pending_question
        # X√≥a c√¢u h·ªèi ƒëang ch·ªù ƒë·ªÉ tr√°nh l·∫∑p l·∫°i
        del st.session_state.pending_question
    else:
        # Tr∆∞·ªùng nh·∫≠p li·ªáu cho ng∆∞·ªùi d√πng
        prompt = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh...", key="user_input")

    if prompt:
        # TƒÉng b·ªô ƒë·∫øm c√¢u h·ªèi
        if "query_count" in st.session_state:
            st.session_state.query_count += 1

        # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ Streamlit (ƒë·ªÉ hi·ªÉn th·ªã v√† l∆∞u state)
        st.session_state.messages.append({"role": "human", "content": prompt})

        # Quan tr·ªçng: Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o history object ƒë·ªÉ c√≥ th·ªÉ format n√≥ sau n√†y
        msgs.add_user_message(prompt)


        # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
        with st.chat_message("human"):
            st.markdown(f"<div class='chat-message user'>{prompt}</div>", unsafe_allow_html=True)

        # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa tr·ª£ l√Ω
        with st.chat_message("assistant"):
            response_container = st.container()

            with response_container:
                st_callback = StreamlitCallbackHandler(st.container())

                try:
                    with st.spinner("ƒêang t√¨m ki·∫øm th√¥ng tin..."):
                        # --- B·∫ÆT ƒê·∫¶U LOGIC FORMAT L·ªäCH S·ª¨ CHAT TH·ª¶ C√îNG ---
                        chat_history_str = ""
                        for msg in msgs.messages[:-1]:
                            if getattr(msg, "type", None) == "human":
                                chat_history_str += f"Human: {msg.content}\n"
                            elif getattr(msg, "type", None) == "ai":
                                chat_history_str += f"AI: {msg.content}\n"
                        # --- K·∫æT TH√öC LOGIC FORMAT L·ªäCH S·ª¨ CHAT TH·ª¶ C√îNG ---

                        # --- DEBUG PRINTS ---
                        print("\n--- DEBUG INFO ---")
                        print(f"Prompt received: {prompt}")
                        print(f"Length of msgs.messages: {len(msgs.messages)}")
                        # Print history messages (optional, can be long)
                        # print("History messages before formatting:")
                        # for msg in msgs.messages[:-1]:
                        #     print(f"  - {msg.role}: {msg.content[:50]}...") # Print truncated
                        print(f"Formatted chat_history_str (first 200 chars): {chat_history_str[:200]}...")
                        print(f"Input dictionary being sent to invoke: {{'query': '{prompt}', 'chat_history': '...'}}") # Avoid printing full history string again
                        print("--- END DEBUG INFO ---\n")
                        # --- END DEBUG PRINTS ---


                        # G·ªçi agent ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi
                        # TRUY·ªÄN R√ï R√ÄNG C·∫¢ "query" v√† "chat_history" v√†o input dictionary
                        response = agent_executor.invoke(
                            {
                                "question": prompt,  # ƒê·∫£m b·∫£o key ƒë√∫ng v·ªõi prompt.input_variables
                                "chat_history": chat_history_str
                            },
                            {"callbacks": [st_callback]}
                        )


                    # L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ response
                    output = response.get("answer") or response.get("result") or "Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi."



                    # Th√™m th√¥ng tin v·ªÅ t√†i li·ªáu ngu·ªìn n·∫øu c√≥
                    if "source_documents" in response and response["source_documents"]:
                        sources = []
                        for i, doc in enumerate(response["source_documents"]):
                            if i >= 3:
                                break
                            metadata = doc.metadata
                            source_info = f"**Ngu·ªìn {i+1}:** "
                            if "ten_tthc" in metadata:
                                source_info += f"{metadata['ten_tthc']}"
                            if "co_quan_thuc_hien" in metadata:
                                source_info += f" - {metadata['co_quan_thuc_hien']}"
                            sources.append(source_info)
                        if sources:
                            output += "\n\n---\n\n**T√†i li·ªáu tham kh·∫£o:**\n" + "\n".join(sources)


                    # Hi·ªÉn th·ªã output v·ªõi styling
                    st.markdown(f"<div class='chat-message bot'>{output}</div>", unsafe_allow_html=True)

                    # Quan tr·ªçng: Th√™m c√¢u tr·∫£ l·ªùi c·ªßa AI v√†o history object ƒë·ªÉ l∆∞·ª£t sau c√≥ l·ªãch s·ª≠
                    msgs.add_ai_message(output)

                except Exception as e:
                    error_msg = f"‚ùå ƒê√£ x·∫£y ra l·ªói: {str(e)}"
                    st.error(error_msg)
                    # Th√™m l·ªói v√†o history object (t√πy ch·ªçn)
                    # msgs.add_ai_message(error_msg)
# H√†m ch√≠nh
def main():
    """H√†m ch√≠nh ƒëi·ªÅu khi·ªÉn to√†n b·ªô ·ª©ng d·ª•ng"""
    # Thi·∫øt l·∫≠p trang
    setup_page()

    # Kh·ªüi t·∫°o m√¥i tr∆∞·ªùng
    load_dotenv()

    # Thi·∫øt l·∫≠p sidebar v√† l·∫•y t√™n collection
    collection_name = setup_sidebar()

    # Thi·∫øt l·∫≠p giao di·ªán chat v√† l·∫•y ƒë·ªëi t∆∞·ª£ng l·ªãch s·ª≠ tin nh·∫Øn Streamlit
    msgs = setup_chat_interface() # V·∫´n c·∫ßn msgs ƒë·ªÉ l∆∞u l·ªãch s·ª≠ Streamlit

    # Ki·ªÉm tra API key
    if check_api_key():
        try:
            # Kh·ªüi t·∫°o retriever
            retriever = get_gemini_retriever(collection_name)

            # Kh·ªüi t·∫°o agent, CH·ªà truy·ªÅn retriever (msgs s·∫Ω ƒë∆∞·ª£c d√πng trong handle_user_input)
            agent_executor = get_gemini_agent(retriever) # <--- S·ª¨A L·∫†I D√íNG N√ÄY

            # X·ª≠ l√Ω ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng
            handle_user_input(msgs, agent_executor) # V·∫´n truy·ªÅn msgs v√†o ƒë√¢y

        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o h·ªá th·ªëng: {str(e)}")
    else:
        st.info("üîë Vui l√≤ng nh·∫≠p Google API Key trong ph·∫ßn C√†i ƒë·∫∑t ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

if __name__ == "__main__":
    main()